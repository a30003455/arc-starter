{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define display options\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the spark instance\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config('spark.executor.memory', '4GB') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read parquet file\n",
    "trips = spark.read.parquet('/home/jovyan/tutorial/data/output/trips.parquet')\n",
    "trips.createOrReplaceTempView('trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first five rows as table\n",
    "trips.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the sql file to ensure same execution in both training and prediction\n",
    "f = open(\"/home/jovyan/tutorial/job/6/trips_enriched.sql\", \"r\")\n",
    "sql = f.read()\n",
    "f.close()\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the sql against spark to generate the new dataframe\n",
    "trips_enriched = spark.sql(sql)\n",
    "trips_enriched.createOrReplaceTempView('trips_enriched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first five rows as table\n",
    "trips_enriched.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random split [75%, 25%] the enriched dataset into two datasets [train_df, test_df]\n",
    "# it is important that the test_df is reserved to test the model against unseen data to test if the model is generalised\n",
    "splits = trips_enriched.randomSplit([3.0, 1.0], 42)\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import *\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml.tuning import *\n",
    "from pyspark.ml.regression import *\n",
    "from pyspark.ml.evaluation import *\n",
    "\n",
    "# create a vector with the input predictor columns\n",
    "vectorAssembler = VectorAssembler(\n",
    "    inputCols=[\"trip_distance\", \"passenger_count\", \"pickup_hour_0\", \"pickup_hour_1\", \"pickup_hour_2\", \"pickup_hour_3\", \"pickup_hour_4\", \"pickup_hour_5\", \"pickup_hour_6\", \"pickup_hour_7\", \"pickup_hour_8\", \"pickup_hour_9\", \"pickup_hour_10\", \"pickup_hour_11\", \"pickup_hour_12\", \"pickup_hour_13\", \"pickup_hour_14\", \"pickup_hour_15\", \"pickup_hour_16\", \"pickup_hour_17\", \"pickup_hour_18\", \"pickup_hour_19\", \"pickup_hour_20\", \"pickup_hour_21\", \"pickup_hour_22\", \"pickup_hour_23\", \"pickup_dayofweek_0\", \"pickup_dayofweek_1\", \"pickup_dayofweek_2\", \"pickup_dayofweek_3\", \"pickup_dayofweek_4\", \"pickup_dayofweek_5\", \"pickup_dayofweek_6\", \"duration\", \"jfk\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "# define the model type to train - in this case a regression model to predict a continuous variable\n",
    "gbt = GBTRegressor(\n",
    "    featuresCol='features', \n",
    "    labelCol='total_amount', \n",
    "    predictionCol='prediction', \n",
    "    maxDepth=5, \n",
    "    maxBins=32, \n",
    "    minInstancesPerNode=1, \n",
    "    minInfoGain=0.0, \n",
    "    maxMemoryInMB=512, \n",
    "    cacheNodeIds=False, \n",
    "    subsamplingRate=1.0, \n",
    "    checkpointInterval=10, \n",
    "    lossType='squared',\n",
    "    maxIter=10,\n",
    "    stepSize=0.1,\n",
    "    seed=None)\n",
    "\n",
    "# define a sequence of stages\n",
    "pipeline = Pipeline(stages=[\n",
    "    vectorAssembler, \\\n",
    "    gbt \\\n",
    "    ])\n",
    "\n",
    "# create a matrix of parameters to try whilst training\n",
    "# parameter grids al\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(param=gbt.maxIter, values=[20, 30]) \\\n",
    "    .addGrid(param=gbt.maxBins, values=[32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "# define the evaluation\n",
    "# this is testing prediction vs total_amount difference using the root mean square error metric\n",
    "regressionEvaluator = RegressionEvaluator(\n",
    "    predictionCol='prediction', \n",
    "    labelCol='total_amount', \n",
    "    metricName='rmse')\n",
    "\n",
    "# set up the model for running\n",
    "crossValidator = CrossValidator(\n",
    "    estimator = pipeline,\n",
    "    estimatorParamMaps = paramGrid,\n",
    "    evaluator = regressionEvaluator,\n",
    "    numFolds = 3,\n",
    "    collectSubModels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the training on the train_df\n",
    "crossValidatorModel = crossValidator.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to demonstrate how the training works loop through all the sub models and print parameters and result\n",
    "# you can see that this is a brute force parameter search. This means the more .addGrid() parameters tested will result in longer training time\n",
    "for fold, foldModel in enumerate(crossValidatorModel.subModels, start=1):\n",
    "    for grid, gridModel in enumerate(foldModel, start=1):\n",
    "        prediction = gridModel.transform(train_df)\n",
    "        rmse = regressionEvaluator.evaluate(prediction)\n",
    "        maxBins = gridModel.stages[-1]._java_obj.getMaxBins()\n",
    "        maxIter = gridModel.stages[-1]._java_obj.getMaxIter()\n",
    "        print(f'{{\"fold\": {fold}, \"grid\": {grid}, \"maxBins\": {maxBins}, \"maxIter\": {maxIter} \"rmse\": {rmse}}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the best/most generalised model\n",
    "pipelineModel = crossValidatorModel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the test dataset to test the model on unseen data\n",
    "prediction = pipelineModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the best model parameters from the pipelineModel to help reduce future number of training runs\n",
    "rmse = regressionEvaluator.evaluate(prediction)\n",
    "maxBins = pipelineModel.stages[-1]._java_obj.getMaxBins()\n",
    "maxIter = pipelineModel.stages[-1]._java_obj.getMaxIter()\n",
    "f'{{\"maxBins\": {maxBins}, \"maxIter\": {maxIter} \"rmse\": {rmse}}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write model for inference via arc\n",
    "pipelineModel \\\n",
    "    .write() \\\n",
    "    .overwrite() \\\n",
    "    .save('/home/jovyan/tutorial/job/6/trips_enriched.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model for inference via python\n",
    "pipelineModel = PipelineModel.load('/home/jovyan/tutorial/job/6/trips_enriched.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform a dataset and show some results\n",
    "trips_prediction = pipelineModel.transform(trips_enriched)\n",
    "trips_prediction.select(\"fare_amount\", \"prediction\").limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
